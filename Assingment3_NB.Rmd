---
title: "Assingment3_NayesBayes"
output: html_document
---
<i>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
library(e1071)
library(ISLR)
library(caret)
library(FNN)
library(gmodels)

library(pivottabler)

library(reshape)

library(reshape2)

```
The file UniversalBank.csv contains data on 5000 customers of Universal Bank. The data include customer
demographic information (age, income, etc.), the customer’s relationship with the bank (mortgage,
securities account, etc.), and the customer response to the last personal loan campaign (Personal Loan).
Among these 5000 customers, only 480 (= 9.6%) accepted the personal loan that was offered to them in
the earlier campaign. In this exercise, we focus on two predictors: Online (whether or not the customer is
an active user of online banking services) and Credit Card (abbreviated CC below) (does the customer
hold a credit card issued by the bank), and the outcome Personal Loan (abbreviated Loan below).
Partition the data into training (60%) and validation (40%) sets.
```{r }
UniversalBank <- read.csv("C:\\Users\\admin\\Downloads\\UniversalBank.csv")

set.seed(15)

UniversalBank$Personal.Loan = as.factor(UniversalBank$Personal.Loan)

UniversalBank$Online = as.factor(UniversalBank$Online)

UniversalBank$CreditCard = as.factor(UniversalBank$CreditCard)
set.seed(15)


Index <- createDataPartition(UniversalBank$Income, p = 0.6, list = FALSE)

trainingData <- UniversalBank[Index,]

set.seed(15)


testData <- UniversalBank[-Index,]




```
A. Create a pivot table for the training data with Online as a column variable, CC as a row variable,
and Loan as a secondary row variable. The values inside the table should convey the count. In R
use functions melt() and cast(), or function table(). In Python, use panda dataframe methods melt()
and pivot().
```{r }
set.seed(15)
Melt_training = melt(trainingData,id=c("CreditCard","Personal.Loan"),variable= "Online")

cast_training=dcast(Melt_training,CreditCard+Personal.Loan~Online)
set.seed(15)
cast_training <-cast_training[c(1,2,14)]

cast_training
set.seed(15)

```

B. Consider the task of classifying a customer who owns a bank credit card and is actively using
online banking services. Looking at the pivot table, what is the probability that this customer will
accept the loan offer? [This is the probability of loan acceptance (Loan = 1) conditional on having
a bank credit card (CC = 1) and being an active user of online banking services (Online = 1)].


<b>Answer.<i>
Possibility of getting a loan if you have a bank credit card and use online services is 84/814 = 0.10319410319
</i></b>
  
C. Create two separate pivot tables for the training data. One will have Loan (rows) as a function of
Online (columns) and the other will have Loan (rows) as a function of CC.
```{r}
set.seed(15)

Melt_training1 <- melt(trainingData,id=c("Personal.Loan"),variable = "Online")

cast_training1  <- dcast(Melt_training1,Personal.Loan~Online)

cast_training1 <-cast_training1[c(1,13)]

cast_training1

set.seed(15)

Melt_training2 <- melt(trainingData,id=c("CreditCard"),variable = "Online")

cast_training2 <- dcast(Melt_training2,CreditCard~Online)

cast_training2 <-cast_training2[c(1,14)]

cast_training2

```
D. Compute the following quantities [P(A | B) means “the probability ofA given B”]:
i. P(CC = 1 | Loan = 1) (the proportion of credit card holders among the loan acceptors)
ii. P(Online = 1 | Loan = 1)
iii. P(Loan = 1) (the proportion of loan acceptors)
iv. P(CC = 1 | Loan = 0)
v. P(Online = 1 | Loan = 0)
vi. P(Loan = 0)

```{r}
set.seed(15)
trainingData1 <- trainingData[c(13,10,14)]



table(trainingData1[,c(3,2)])

#I) 84/(84+200) =  0.29577464788

#IV)  814/(814+1904) = 0.29948491537



table(trainingData1[,c(1,2)])

#II)  172/(112+172) = 0.60563380281

#V) 1610/(1610+1108) = 0.5923473142



table(trainingData1[,c(2)])

#III) 284/(284+2718) = 0.0946035976

#VI)  2718/(284+2693) = 0.91299966409

set.seed(15)
```
E. Use the quantities computed above to compute the naive Bayes probability P(Loan = 1 | CC = 1,
Online = 1).

```{r}
# calculation using above values as below

#0.29577464788 * 0.60563380281 * 0.0946035976/((0.0946035976 * 0.60563380281 * 0.29577464788) +( 0.91299966409 * 0.5923473142 * 0.29948491537))
```

<b>Answer.<i> 0.09471959475</i></b>

F. Compare this value with the one obtained from the pivot table in (B). Which is a more accurate
estimate?


<b>Answer.<i>
The distinction between the exact and naive bayes methods is that the exact method requires the exact same independent variable classifications to estimate, while the naive bayes method does not i.e. 9.4% for naive bayes and 10.3% for exact method.
</i></b>



G. Which of the entries in this table are needed for computing P(Loan = 1 | CC = 1, Online = 1)? Run
naive Bayes on the data. Examine the model output on training data, and find the entry that
corresponds to P(Loan = 1 | CC = 1, Online = 1). Compare this to the number you obtained in (E)
```{r}
set.seed(15)

naivebayes = naiveBayes(Personal.Loan~.,data=trainingData1)

naivebayes

set.seed(15)
```
0.2957746 * 0.6056338 * 0.0946036 /((0.0946035976 * 0.60563380281 * 0.29577464788) +( 0.2994849 * 0.5923473 * 0.9053964 ))

which gives <b><i>0.09543910129</i></b>

<ins><b>Hence we can say that the results of naive bayes are similar to those of the previous methods i.e 0.09543910129 & which is the same as the previous response  0.09471959475 in E.).</b></ins>
